{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\alpha^2\n",
    "\\end{align}\n",
    "* Need to learn word encodings\n",
    "* Finally got the scikit one hot encoding from youtube data school. Also showed how pipeline is done. Its great. In Pandas playlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding from https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define documents\n",
    "docs = ['Well done!',\n",
    "        'Good work',\n",
    "        'Great effort',\n",
    "        'nice work',\n",
    "        'Excellent!',\n",
    "        'Weak',\n",
    "        'Poor effort!',\n",
    "        'not good',\n",
    "        'poor work',\n",
    "        'Could have done better.']\n",
    "# define class labels\n",
    "labels = np.array([1,1,1,1,1,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=50\n",
    "embedding_dimension=8\n",
    "encoded_docs=[K.preprocessing.text.one_hot(d, vocab_size) for d in docs]\n",
    "max_len=4\n",
    "pad_docs=K.preprocessing.sequence.pad_sequences(encoded_docs, maxlen=max_len, padding='post')\n",
    "#the model\n",
    "model=K.models.Sequential()\n",
    "model.add(K.layers.Embedding(vocab_size,embedding_dimension,input_length=max_len))\n",
    "model.add(K.layers.Flatten())\n",
    "model.add(K.layers.Dense(1,activation='sigmoid'))\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "history=model.fit(pad_docs, labels, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,accuracy=model.evaluate([[21,6,0,0]],[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 \n",
    "SKlearn one hot encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "docs = ['Well done!',\n",
    "        'Good work',\n",
    "        'Great effort',\n",
    "        'nice work',\n",
    "        'Excellent!',\n",
    "        'Weak',\n",
    "        'Poor effort!',\n",
    "        'not good',\n",
    "        'poor work',\n",
    "        'Could have done better.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['work', 'done!', 'could', 'effort', 'have', 'done', 'excellent!', 'poor', 'great', 'weak', 'not', 'nice', 'well', 'effort!', 'good', 'better.']\n"
     ]
    }
   ],
   "source": [
    "vocab=set()\n",
    "toks=[y.split(\" \") for y in docs]\n",
    "ohe=preprocessing.OneHotEncoder()\n",
    "for d in toks:\n",
    "    for x in d:\n",
    "        vocab.add(x.lower())\n",
    "vocab=list(vocab)\n",
    "print(vocab)\n",
    "vocab.sort()\n",
    "vocab=pd.DataFrame(vocab)\n",
    "X=ohe.fit_transform(vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['better.', 'could', 'done', 'done!', 'effort', 'effort!',\n",
       "        'excellent!', 'good', 'great', 'have', 'nice', 'not', 'poor',\n",
       "        'weak', 'well', 'work'], dtype=object)]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 11.]\n",
      " [ 22.]\n",
      " [ 33.]\n",
      " [ 44.]\n",
      " [ 55.]\n",
      " [ 66.]\n",
      " [ 77.]\n",
      " [ 88.]\n",
      " [ 99.]\n",
      " [111.]\n",
      " [222.]\n",
      " [333.]\n",
      " [444.]\n",
      " [555.]\n",
      " [666.]\n",
      " [777.]]\n"
     ]
    }
   ],
   "source": [
    "print(np.dot(X.toarray(),np.array([11,22,33,44,55,66,77,88,99,111,222,333,444,555,666,777]).reshape(16,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 11],\n",
       "       [ 22],\n",
       "       [ 33],\n",
       "       [ 44],\n",
       "       [ 55],\n",
       "       [ 66],\n",
       "       [ 77],\n",
       "       [ 88],\n",
       "       [ 99],\n",
       "       [111],\n",
       "       [222],\n",
       "       [333],\n",
       "       [444],\n",
       "       [555],\n",
       "       [666],\n",
       "       [777]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([11,22,33,44,55,66,77,88,99,111,222,333,444,555,666,777]).reshape(16,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
